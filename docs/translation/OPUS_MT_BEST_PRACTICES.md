# OPUS-MT ONNX Runtime æœ€ä½³å¯¦è¸æŒ‡å—

## ğŸ“‹ é©ç”¨æ–¼æˆ‘å€‘çš„å°ˆæ¡ˆ

æœ¬æ–‡æª”é‡å°æˆ‘å€‘å°ˆæ¡ˆçš„ç‰¹å®šæƒ…æ³ï¼š
- **æ¨¡å‹**: opus-mt-en-zh (ONNX æ ¼å¼)
- **é‹è¡Œç’°å¢ƒ**: ONNX Runtime (Rust, ort crate)
- **æ¶æ§‹**: Encoder-Decoder (MarianMT)
- **å·²çŸ¥å•é¡Œ**: Token 8 é‡è¤‡å¾ªç’°ã€ç©ºè¼¸å‡º

---

## ğŸ¯ æ ¸å¿ƒæœ€ä½³å¯¦è¸

### 1. ç”Ÿæˆç­–ç•¥é¸æ“‡

#### ç­–ç•¥ 1: æ ¹æ“šè¼¸å…¥é•·åº¦å‹•æ…‹é¸æ“‡ â­â­â­â­â­

**å¯¦ç¾**ï¼š
```rust
let next_token_id = if text.len() < 20 {
    // çŸ­å¥ï¼šä½¿ç”¨ Top-p æ¡æ¨£ï¼ˆé¿å…é‡è¤‡ï¼‰
    Self::sample_top_p(last_logits, 0.7, 0.9)?
} else {
    // ä¸­ç­‰å’Œé•·å¥ï¼šä½¿ç”¨ Greedy decodingï¼ˆä¿æŒæº–ç¢ºæ€§ï¼‰
    max_idx as i64
};
```

**åŸå› **ï¼š
- çŸ­å¥å®¹æ˜“é™·å…¥é‡è¤‡å¾ªç’°ï¼Œéœ€è¦æ¡æ¨£å¢åŠ å¤šæ¨£æ€§
- é•·å¥éœ€è¦ä¿æŒæº–ç¢ºæ€§ï¼Œä½¿ç”¨ Greedy æ›´ç©©å®š

**åƒæ•¸å»ºè­°**ï¼š
- çŸ­å¥é–¾å€¼ï¼š`< 20` å­—ç¬¦
- Temperature: `0.7`
- Top-p: `0.9`

#### ç­–ç•¥ 2: å¯¦æ–½é‡è¤‡å¾ªç’°æª¢æ¸¬ â­â­â­â­â­

**å¯¦ç¾**ï¼š
```rust
let mut consecutive_same = 0;
let mut last_token: Option<i64> = None;

for step in 0..max_length {
    let next_token_id = /* é¸æ“‡ token */;
    
    // æª¢æ¸¬é‡è¤‡
    if Some(next_token_id) == last_token {
        consecutive_same += 1;
        if consecutive_same >= 3 {
            // å¼·åˆ¶çµ‚æ­¢æˆ–é¸æ“‡æ¬¡å„ª token
            println!("[TranslationModel] è­¦å‘Šï¼šæª¢æ¸¬åˆ°é‡è¤‡å¾ªç’°ï¼Œçµ‚æ­¢ç”Ÿæˆ");
            break;
        }
    } else {
        consecutive_same = 0;
    }
    
    last_token = Some(next_token_id);
    generated_ids.push(next_token_id);
}
```

**åŸå› **ï¼š
- é˜²æ­¢æ¨¡å‹é™·å…¥ç„¡é™å¾ªç’°
- ç‰¹åˆ¥æ˜¯ Token 8 é‡è¤‡å•é¡Œ
- å¯ä»¥ç«‹å³çµ‚æ­¢ç•°å¸¸ç”Ÿæˆ

**åƒæ•¸å»ºè­°**ï¼š
- é‡è¤‡é–¾å€¼ï¼š`>= 3` æ¬¡é€£çºŒç›¸åŒ

#### ç­–ç•¥ 3: å¯¦æ–½ Repetition Penalty â­â­â­â­â­

**å¯¦ç¾**ï¼š
```rust
// æ‡‰ç”¨é‡è¤‡æ‡²ç½°
let repetition_penalty = 1.2; // é™ä½ 20%
let mut penalized_logits = logits.to_vec();

for token_id in &generated_tokens {
    let idx = *token_id as usize;
    if idx < penalized_logits.len() {
        penalized_logits[idx] /= repetition_penalty;
    }
}

// å¾æ‡²ç½°å¾Œçš„ logits é¸æ“‡ token
let next_token_id = argmax(&penalized_logits);
```

**åŸå› **ï¼š
- æ¨™æº–è§£æ±ºæ–¹æ¡ˆï¼Œå»£æ³›ä½¿ç”¨
- å¯ä»¥æœ‰æ•ˆé˜²æ­¢é‡è¤‡ç”Ÿæˆ
- ä¸å½±éŸ¿æ­£å¸¸ç¿»è­¯

**åƒæ•¸å»ºè­°**ï¼š
- Repetition Penalty: `1.2` (é™ä½ 20%)
- å¯ä»¥æ ¹æ“šå¯¦éš›æ•ˆæœèª¿æ•´

### 2. ç‰¹æ®Š Token è™•ç†

#### Token 8 ç‰¹æ®Šè™•ç† â­â­â­â­

**å•é¡Œ**ï¼š
- Token 8 å°æ‡‰ç©ºå­—ç¬¦ä¸²
- å®¹æ˜“é™·å…¥é‡è¤‡å¾ªç’°
- å°è‡´ç©ºè¼¸å‡º

**è§£æ±ºæ–¹æ¡ˆ**ï¼š
```rust
// å¦‚æœé¸æ“‡äº† Token 8ï¼Œæª¢æŸ¥æ˜¯å¦æ‡‰è©²è·³é
if next_token_id == 8 {
    // æª¢æŸ¥ Token 8 çš„ logit æ˜¯å¦ç•°å¸¸é«˜
    let token_8_logit = last_logits[8];
    let (second_idx, second_logit) = /* æ‰¾åˆ°æ¬¡å„ª token */;
    
    if (token_8_logit - second_logit) > 2.0 {
        // Token 8 çš„å„ªå‹¢å¤ªå¤§ï¼Œå¯èƒ½æ˜¯ç•°å¸¸ï¼Œé¸æ“‡æ¬¡å„ª
        println!("[TranslationModel] è­¦å‘Šï¼šToken 8 logit ç•°å¸¸é«˜ï¼Œé¸æ“‡æ¬¡å„ª token");
        next_token_id = second_idx as i64;
    }
}
```

**åŸå› **ï¼š
- Token 8 æ˜¯æˆ‘å€‘ç™¼ç¾çš„ä¸»è¦å•é¡Œæºé ­
- éœ€è¦ç‰¹åˆ¥è™•ç†
- å¯ä»¥é˜²æ­¢ç©ºè¼¸å‡º

#### EOS Token è™•ç† â­â­â­â­â­

**å¯¦ç¾**ï¼š
```rust
// æª¢æŸ¥æ˜¯å¦é”åˆ° EOS
if next_token_id == eos_token_id {
    println!("[TranslationModel] é”åˆ° EOS tokenï¼Œåœæ­¢ç”Ÿæˆ");
    break;
}

// ç¢ºä¿ä¸æœƒç„¡é™ç”Ÿæˆ
if generated_ids.len() > max_length {
    println!("[TranslationModel] è­¦å‘Šï¼šé”åˆ°æœ€å¤§é•·åº¦ï¼Œå¼·åˆ¶åœæ­¢");
    break;
}
```

**åŸå› **ï¼š
- æ­£å¸¸çµ‚æ­¢æ¢ä»¶
- é˜²æ­¢ç„¡é™ç”Ÿæˆ
- ä¿è­·ç³»çµ±è³‡æº

### 3. éŒ¯èª¤è™•ç†å’Œé™ç´š

#### ç©ºè¼¸å‡ºæª¢æ¸¬ â­â­â­â­â­

**å¯¦ç¾**ï¼š
```rust
// æª¢æŸ¥è¼¸å‡ºæ˜¯å¦ç‚ºç©º
if output_ids.is_empty() {
    return Err("ç¿»è­¯çµæœç‚ºç©º".to_string());
}

// æª¢æŸ¥è§£ç¢¼å¾Œçš„æ–‡æœ¬
let decoded = tokenizer.decode(&output_ids, true)?;
if decoded.trim().is_empty() {
    // å˜—è©¦ä½¿ç”¨å‚™ç”¨ç­–ç•¥
    return self.translate_with_fallback(text, source_lang, target_lang).await;
}
```

**é™ç´šç­–ç•¥**ï¼š
```rust
async fn translate_with_fallback(
    &self,
    text: &str,
    source_lang: &str,
    target_lang: &str,
) -> Result<String, String> {
    // 1. å˜—è©¦ä½¿ç”¨ Temperature æ¡æ¨£
    match self.translate_with_temperature(text, 0.8).await {
        Ok(result) if !result.trim().is_empty() => Ok(result),
        _ => {}
    }
    
    // 2. å˜—è©¦åˆ†æ®µç¿»è­¯
    match self.translate_segmented(text).await {
        Ok(result) if !result.trim().is_empty() => Ok(result),
        _ => {}
    }
    
    // 3. è¿”å›éŒ¯èª¤æˆ–ä½¿ç”¨è©å…¸ç¿»è­¯
    Err("ç„¡æ³•ç”Ÿæˆæœ‰æ•ˆç¿»è­¯".to_string())
}
```

**åŸå› **ï¼š
- æä¾›å¤šå±¤ä¿è­·
- æé«˜ç³»çµ±ç©©å®šæ€§
- æ”¹å–„ç”¨æˆ¶é«”é©—

### 4. æ€§èƒ½å„ªåŒ–

#### æ‰¹é‡è™•ç† â­â­â­

**å¯¦ç¾**ï¼š
```rust
// å¦‚æœæœ‰å¤šå€‹æ–‡æœ¬ï¼Œè€ƒæ…®æ‰¹é‡è™•ç†
// ä½† ONNX Runtime éœ€è¦æ‰‹å‹•å¯¦ç¾æ‰¹è™•ç†
// ç•¶å‰å¯¦ç¾æ˜¯å–®å€‹è™•ç†
```

**æ³¨æ„**ï¼š
- ONNX Runtime æ”¯æŒæ‰¹è™•ç†
- ä½†éœ€è¦èª¿æ•´è¼¸å…¥å¼µé‡å½¢ç‹€
- ç•¶å‰å¯¦ç¾æ˜¯å–®å€‹è™•ç†ï¼Œè¶³å¤ ä½¿ç”¨

#### ç·©å­˜ Encoder è¼¸å‡º â­â­â­â­

**å¯¦ç¾**ï¼š
```rust
// å¦‚æœå¤šæ¬¡ç¿»è­¯ç›¸åŒæ–‡æœ¬ï¼Œå¯ä»¥ç·©å­˜ encoder è¼¸å‡º
// ä½†å°æ–¼ä¸åŒæ–‡æœ¬ï¼Œæ¯æ¬¡éƒ½éœ€è¦é‡æ–°è¨ˆç®—
```

**æ³¨æ„**ï¼š
- å°æ–¼ç›¸åŒæ–‡æœ¬çš„å¤šæ¬¡ç¿»è­¯ï¼Œå¯ä»¥ç·©å­˜
- ä½†å¯¦éš›ä½¿ç”¨ä¸­å¾ˆå°‘é‡åˆ°
- ç•¶å‰å¯¦ç¾ä¸éœ€è¦å„ªåŒ–

### 5. èª¿è©¦å’Œç›£æ§

#### è©³ç´°æ—¥èªŒ â­â­â­â­â­

**å¯¦ç¾**ï¼š
```rust
println!("[TranslationModel] è¼¸å…¥æ–‡æœ¬: {}", text);
println!("[TranslationModel] Tokenization çµæœ: {:?}", input_ids);
println!("[TranslationModel] Encoder hidden states shape: {:?}", encoder_shape);
println!("[TranslationModel] æ­¥é©Ÿ {}: ä¸‹ä¸€å€‹ token ID = {}", step, next_token_id);
println!("[TranslationModel] ç”Ÿæˆçš„ token IDs: {:?}", generated_ids);
println!("[TranslationModel] æœ€çµ‚çµæœ: {}", translated);
```

**åŸå› **ï¼š
- å¹«åŠ©èª¿è©¦å•é¡Œ
- ç›£æ§ç”Ÿæˆéç¨‹
- ç™¼ç¾ç•°å¸¸è¡Œç‚º

**å»ºè­°**ï¼š
- åœ¨é–‹ç™¼ç’°å¢ƒå•Ÿç”¨è©³ç´°æ—¥èªŒ
- åœ¨ç”Ÿç”¢ç’°å¢ƒå¯ä»¥æ¸›å°‘æ—¥èªŒ
- ä½¿ç”¨æ—¥èªŒç´šåˆ¥æ§åˆ¶

#### çµ±è¨ˆä¿¡æ¯ â­â­â­â­

**å¯¦ç¾**ï¼š
```rust
struct TranslationStats {
    total_translations: usize,
    empty_outputs: usize,
    repetition_loops: usize,
    average_length: f32,
}

// è¨˜éŒ„çµ±è¨ˆä¿¡æ¯
stats.total_translations += 1;
if translated.is_empty() {
    stats.empty_outputs += 1;
}
```

**åŸå› **ï¼š
- ç›£æ§ç³»çµ±å¥åº·ç‹€æ³
- ç™¼ç¾å•é¡Œè¶¨å‹¢
- å„ªåŒ–åƒæ•¸

### 6. ä»£ç¢¼çµ„ç¹”

#### æ¨¡å¡ŠåŒ–è¨­è¨ˆ â­â­â­â­â­

**å»ºè­°çµæ§‹**ï¼š
```rust
impl TranslationModel {
    // æ ¸å¿ƒç¿»è­¯æ–¹æ³•
    pub async fn translate(...) -> Result<String, String>
    
    // æ¡æ¨£æ–¹æ³•
    fn sample_top_p(...) -> Result<i64, String>
    fn sample_temperature(...) -> Result<i64, String>
    
    // è¼”åŠ©æ–¹æ³•
    fn apply_repetition_penalty(...)
    fn detect_repetition_loop(...) -> bool
    fn handle_empty_output(...) -> Result<String, String>
}
```

**åŸå› **ï¼š
- ä»£ç¢¼æ¸…æ™°æ˜“ç¶­è­·
- æ˜“æ–¼æ¸¬è©¦
- æ˜“æ–¼æ“´å±•

#### é…ç½®åƒæ•¸åŒ– â­â­â­â­â­

**å¯¦ç¾**ï¼š
```rust
struct GenerationConfig {
    max_length: usize,
    temperature: f32,
    top_p: f32,
    repetition_penalty: f32,
    short_sentence_threshold: usize,
    repetition_threshold: usize,
}

impl Default for GenerationConfig {
    fn default() -> Self {
        Self {
            max_length: 150,
            temperature: 0.7,
            top_p: 0.9,
            repetition_penalty: 1.2,
            short_sentence_threshold: 20,
            repetition_threshold: 3,
        }
    }
}
```

**åŸå› **ï¼š
- æ˜“æ–¼èª¿æ•´åƒæ•¸
- å¯ä»¥é‡å°ä¸åŒå ´æ™¯ä½¿ç”¨ä¸åŒé…ç½®
- æ–¹ä¾¿æ¸¬è©¦å’Œå„ªåŒ–

### 7. æ¸¬è©¦ç­–ç•¥

#### å–®å…ƒæ¸¬è©¦ â­â­â­â­â­

**æ¸¬è©¦å…§å®¹**ï¼š
```rust
#[cfg(test)]
mod tests {
    #[test]
    fn test_repetition_detection() {
        // æ¸¬è©¦é‡è¤‡æª¢æ¸¬é‚è¼¯
    }
    
    #[test]
    fn test_repetition_penalty() {
        // æ¸¬è©¦é‡è¤‡æ‡²ç½°æ‡‰ç”¨
    }
    
    #[test]
    fn test_top_p_sampling() {
        // æ¸¬è©¦ Top-p æ¡æ¨£
    }
    
    #[test]
    fn test_empty_output_detection() {
        // æ¸¬è©¦ç©ºè¼¸å‡ºæª¢æ¸¬
    }
}
```

**åŸå› **ï¼š
- ç¢ºä¿åŠŸèƒ½æ­£ç¢º
- é˜²æ­¢å›æ­¸
- æé«˜ä»£ç¢¼è³ªé‡

#### é›†æˆæ¸¬è©¦ â­â­â­â­â­

**æ¸¬è©¦å…§å®¹**ï¼š
```rust
#[tokio::test]
async fn test_translation_comprehensive() {
    let test_cases = vec![
        "Hello",                           // çŸ­å¥
        "Hello world",                     // çŸ­å¥ï¼ˆæ›¾ç¶“ç©ºè¼¸å‡ºï¼‰
        "The quick brown fox...",          // é•·å¥ï¼ˆæ›¾ç¶“ç©ºè¼¸å‡ºï¼‰
        "Machine learning is...",          // é•·å¥ï¼ˆæ›¾ç¶“ç©ºè¼¸å‡ºï¼‰
    ];
    
    for text in test_cases {
        let result = model.translate(text, "en", "zh").await;
        assert!(result.is_ok());
        assert!(!result.unwrap().trim().is_empty());
    }
}
```

**åŸå› **ï¼š
- æ¸¬è©¦å®Œæ•´æµç¨‹
- é©—è­‰ä¿®å¾©æ•ˆæœ
- ç¢ºä¿ç©©å®šæ€§

### 8. å¯¦æ–½å„ªå…ˆç´š

#### éšæ®µ 1: ç«‹å³å¯¦æ–½ï¼ˆå·²å®Œæˆéƒ¨åˆ†ï¼‰âœ…
- [x] Top-p æ¡æ¨£ï¼ˆçŸ­å¥ï¼‰
- [x] Greedy decodingï¼ˆé•·å¥ï¼‰
- [ ] é‡è¤‡å¾ªç’°æª¢æ¸¬
- [ ] ç©ºè¼¸å‡ºæª¢æ¸¬

#### éšæ®µ 2: çŸ­æœŸå¯¦æ–½ï¼ˆ1-2é€±ï¼‰
- [ ] Repetition Penalty
- [ ] Token 8 ç‰¹æ®Šè™•ç†
- [ ] é™ç´šç­–ç•¥
- [ ] è©³ç´°æ—¥èªŒ

#### éšæ®µ 3: é•·æœŸå„ªåŒ–ï¼ˆæŒçºŒï¼‰
- [ ] åƒæ•¸èª¿å„ª
- [ ] æ€§èƒ½å„ªåŒ–
- [ ] çµ±è¨ˆç›£æ§
- [ ] æ–‡æª”å®Œå–„

### 9. åƒæ•¸å»ºè­°

#### ç•¶å‰æ¨è–¦é…ç½®

```rust
GenerationConfig {
    max_length: 150,                    // æœ€å¤§ç”Ÿæˆé•·åº¦
    temperature: 0.7,                   // æº«åº¦ï¼ˆç”¨æ–¼æ¡æ¨£ï¼‰
    top_p: 0.9,                         // Top-p æ¡æ¨£åƒæ•¸
    repetition_penalty: 1.2,            // é‡è¤‡æ‡²ç½°ï¼ˆé™ä½ 20%ï¼‰
    short_sentence_threshold: 20,        // çŸ­å¥é–¾å€¼ï¼ˆå­—ç¬¦æ•¸ï¼‰
    repetition_threshold: 3,             // é‡è¤‡æª¢æ¸¬é–¾å€¼ï¼ˆæ¬¡æ•¸ï¼‰
}
```

#### æ ¹æ“šå¯¦éš›æ•ˆæœèª¿æ•´

**å¦‚æœä»ç„¶æœ‰é‡è¤‡å•é¡Œ**ï¼š
- æé«˜ `repetition_penalty` åˆ° `1.3` æˆ– `1.4`
- é™ä½ `repetition_threshold` åˆ° `2`

**å¦‚æœç¿»è­¯è³ªé‡ä¸‹é™**ï¼š
- é™ä½ `temperature` åˆ° `0.6`
- æé«˜ `top_p` åˆ° `0.95`

**å¦‚æœç©ºè¼¸å‡ºä»ç„¶å­˜åœ¨**ï¼š
- å¢åŠ  `short_sentence_threshold` åˆ° `30`
- å°æ‰€æœ‰è¼¸å…¥ä½¿ç”¨ Temperature æ¡æ¨£

### 10. å¸¸è¦‹å•é¡Œå’Œè§£æ±ºæ–¹æ¡ˆ

#### Q1: ç‚ºä»€éº¼çŸ­å¥ä½¿ç”¨ Top-pï¼Œé•·å¥ä½¿ç”¨ Greedyï¼Ÿ

**A**: 
- çŸ­å¥å®¹æ˜“é™·å…¥é‡è¤‡å¾ªç’°ï¼Œéœ€è¦æ¡æ¨£å¢åŠ å¤šæ¨£æ€§
- é•·å¥éœ€è¦ä¿æŒæº–ç¢ºæ€§ï¼ŒGreedy æ›´ç©©å®š
- é€™æ˜¯åŸºæ–¼å¯¦éš›æ¸¬è©¦çš„çµæœ

#### Q2: Repetition Penalty æ‡‰è©²æ‡‰ç”¨åœ¨å“ªè£¡ï¼Ÿ

**A**:
- åœ¨é¸æ“‡ token ä¹‹å‰æ‡‰ç”¨
- å°æ‰€æœ‰å·²ç”Ÿæˆçš„ token æ‡‰ç”¨æ‡²ç½°
- åªé™ä½ logitï¼Œä¸æ”¹è®Šé †åº

#### Q3: å¦‚ä½•è™•ç† Token 8 å•é¡Œï¼Ÿ

**A**:
- æª¢æ¸¬ Token 8 çš„ logit æ˜¯å¦ç•°å¸¸é«˜
- å¦‚æœç•°å¸¸ï¼Œé¸æ“‡æ¬¡å„ª token
- æˆ–è€…å®Œå…¨ç¦æ­¢é¸æ“‡ Token 8ï¼ˆé™¤éæ²’æœ‰å…¶ä»–é¸æ“‡ï¼‰

#### Q4: ç©ºè¼¸å‡ºæ™‚æ‡‰è©²æ€éº¼è¾¦ï¼Ÿ

**A**:
1. æª¢æ¸¬ç©ºè¼¸å‡º
2. å˜—è©¦ä½¿ç”¨å‚™ç”¨ç­–ç•¥ï¼ˆTemperature æ¡æ¨£ï¼‰
3. å¦‚æœä»ç„¶å¤±æ•—ï¼Œè¿”å›éŒ¯èª¤æˆ–ä½¿ç”¨è©å…¸ç¿»è­¯

### 11. ä»£ç¢¼ç¤ºä¾‹

#### å®Œæ•´çš„ç”Ÿæˆå¾ªç’°ï¼ˆæ¨è–¦å¯¦ç¾ï¼‰

```rust
pub async fn translate(...) -> Result<String, String> {
    // ... encoder æ¨ç† ...
    
    let config = GenerationConfig::default();
    let mut generated_ids = vec![decoder_start_token_id];
    let mut consecutive_same = 0;
    let mut last_token: Option<i64> = None;
    
    for step in 0..config.max_length {
        // ... decoder æ¨ç†ï¼Œç²å– logits ...
        
        // 1. æ‡‰ç”¨é‡è¤‡æ‡²ç½°
        let mut penalized_logits = last_logits.to_vec();
        Self::apply_repetition_penalty(
            &mut penalized_logits,
            &generated_ids,
            config.repetition_penalty
        );
        
        // 2. é¸æ“‡ tokenï¼ˆæ ¹æ“šè¼¸å…¥é•·åº¦ï¼‰
        let next_token_id = if text.len() < config.short_sentence_threshold {
            Self::sample_top_p(&penalized_logits, config.temperature, config.top_p)?
        } else {
            Self::greedy_decode(&penalized_logits)?
        };
        
        // 3. æª¢æ¸¬é‡è¤‡å¾ªç’°
        if Some(next_token_id) == last_token {
            consecutive_same += 1;
            if consecutive_same >= config.repetition_threshold {
                println!("[TranslationModel] è­¦å‘Šï¼šæª¢æ¸¬åˆ°é‡è¤‡å¾ªç’°ï¼Œçµ‚æ­¢ç”Ÿæˆ");
                break;
            }
        } else {
            consecutive_same = 0;
        }
        
        // 4. æª¢æŸ¥ EOS
        if next_token_id == eos_token_id {
            break;
        }
        
        last_token = Some(next_token_id);
        generated_ids.push(next_token_id);
    }
    
    // 5. è§£ç¢¼å’Œé©—è­‰
    let output_ids = /* è™•ç†ç”Ÿæˆçš„ tokens */;
    let decoded = tokenizer.decode(&output_ids, true)?;
    
    // 6. æª¢æŸ¥ç©ºè¼¸å‡º
    if decoded.trim().is_empty() {
        return self.translate_with_fallback(text, source_lang, target_lang).await;
    }
    
    Ok(decoded.trim().to_string())
}
```

---

## ğŸ“Š ç¸½çµ

### æ ¸å¿ƒåŸå‰‡

1. **å¤šå±¤ä¿è­·**: é‡è¤‡æª¢æ¸¬ + Repetition Penalty + é™ç´šç­–ç•¥
2. **å‹•æ…‹ç­–ç•¥**: æ ¹æ“šè¼¸å…¥é•·åº¦é¸æ“‡ä¸åŒç­–ç•¥
3. **è©³ç´°ç›£æ§**: æ—¥èªŒå’Œçµ±è¨ˆå¹«åŠ©ç™¼ç¾å•é¡Œ
4. **åƒæ•¸åŒ–é…ç½®**: æ˜“æ–¼èª¿æ•´å’Œå„ªåŒ–
5. **éŒ¯èª¤è™•ç†**: å®Œå–„çš„éŒ¯èª¤è™•ç†å’Œé™ç´šæ©Ÿåˆ¶

### å¯¦æ–½å»ºè­°

1. **ç«‹å³å¯¦æ–½**: é‡è¤‡å¾ªç’°æª¢æ¸¬ã€ç©ºè¼¸å‡ºæª¢æ¸¬
2. **çŸ­æœŸå¯¦æ–½**: Repetition Penaltyã€Token 8 ç‰¹æ®Šè™•ç†
3. **é•·æœŸå„ªåŒ–**: åƒæ•¸èª¿å„ªã€æ€§èƒ½å„ªåŒ–ã€ç›£æ§å®Œå–„

### é æœŸæ•ˆæœ

å¯¦æ–½é€™äº›æœ€ä½³å¯¦è¸å¾Œï¼š
- âœ… ç©ºè¼¸å‡ºå•é¡Œï¼šå¾ 12.5% é™ä½åˆ° < 2%
- âœ… é‡è¤‡å•é¡Œï¼šå¾å¸¸è¦‹é™ä½åˆ°ç½•è¦‹
- âœ… ç³»çµ±ç©©å®šæ€§ï¼šå¤§å¹…æå‡
- âœ… ç¿»è­¯è³ªé‡ï¼šä¿æŒæˆ–æå‡

